{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG integration with Azure AI Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing ai search SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-search-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting in the variables with keys and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_key=\"AZURE_AI_SEARCH_KEY\"\n",
    "search_endpoint=\"AZURE_AI_SEARCH_ENDPOINT\"\n",
    "index_name=\"INDEX_NAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating AI Search Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "credential = AzureKeyCredential(search_key)\n",
    "\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "search_client = SearchClient(endpoint=search_endpoint,\n",
    "                      index_name=index_name,\n",
    "                      credential=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataframe and populating it with data from Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# Initialize Spark session (already initialized in Microsoft Fabric notebooks)\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Define schema for the DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"content\", StringType(), True),\n",
    "    StructField(\"metadata_storage_name\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Initialize an empty list to hold rows for the DataFrame\n",
    "data = []\n",
    "\n",
    "# Perform the search\n",
    "results = search_client.search(\n",
    "    query_type=\"simple\",\n",
    "    search_text=\"*\",\n",
    "    include_total_count=True\n",
    ")\n",
    "\n",
    "# Iterate through the results and extract fields\n",
    "for result in results:\n",
    "    data.append((\n",
    "        result.get(\"content\", \"\"),  # Extract content field\n",
    "        result.get(\"metadata_storage_name\", \"\")  # Extract metadata_storage_name field\n",
    "    ))\n",
    "\n",
    "# Create a Spark DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Show the Spark DataFrame\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
