{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning using Hyperopt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Hyperopt in our Python Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset into a spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"Files/diabetes.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "   \n",
    "\n",
    "data = df.dropna().select(col(\"Pregnancies\").astype(\"int\"),\n",
    "                           col(\"Glucose\").astype(\"int\"),\n",
    "                          col(\"BloodPressure\").astype(\"int\"),\n",
    "                          col(\"SkinThickness\").astype(\"int\"),\n",
    "                          col(\"Insulin\").astype(\"int\"),\n",
    "                          col(\"BMI\").astype(\"float\"),\n",
    "                          col(\"DiabetesPedigreeFunction\").astype(\"float\"),\n",
    "                          col(\"Age\").astype(\"int\"),\n",
    "                          col(\"Outcome\").astype(\"int\")\n",
    "                          )\n",
    "\n",
    "   \n",
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "print (\"Training Rows:\", train.count(), \" Testing Rows:\", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Hyperopt Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "import mlflow\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "   \n",
    "def objective(params):\n",
    "    # Train a model using the provided hyperparameter value\n",
    "    numFeatures = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]\n",
    "    numVector = VectorAssembler(inputCols=numFeatures, outputCol=\"numericFeatures\")\n",
    "    numScaler = MinMaxScaler(inputCol = numVector.getOutputCol(), outputCol=\"normalizedFeatures\")\n",
    "    featureVector = VectorAssembler(inputCols=[\"normalizedFeatures\"], outputCol=\"Features\")\n",
    "    mlAlgo = DecisionTreeClassifier(labelCol=\"Outcome\",    \n",
    "                                    featuresCol=\"Features\",\n",
    "                                    maxDepth=params['MaxDepth'], maxBins=params['MaxBins'])\n",
    "    pipeline = Pipeline(stages=[numVector, numScaler, featureVector, mlAlgo])\n",
    "    model = pipeline.fit(train)\n",
    "       \n",
    "    # Evaluate the model to get the target metric\n",
    "    prediction = model.transform(test)\n",
    "    eval = MulticlassClassificationEvaluator(labelCol=\"Outcome\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = eval.evaluate(prediction)\n",
    "       \n",
    "    # Hyperopt tries to minimize the objective function, so you must return the negative accuracy.\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Objective Function for Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials\n",
    "from hyperopt import fmin, tpe, hp\n",
    "  \n",
    "search_space = {\n",
    "    'MaxDepth': hp.randint('MaxDepth', 10),\n",
    "    'MaxBins': hp.choice('MaxBins', [10, 20, 30])\n",
    "}\n",
    "\n",
    "algo=tpe.suggest\n",
    "\n",
    "# Create a Trials object to track each run\n",
    "trial_runs = Trials()\n",
    "   \n",
    "argmin = fmin(\n",
    "  fn=objective,\n",
    "  space=search_space,\n",
    "  algo=algo,\n",
    "  max_evals=3,\n",
    "  trials=trial_runs)\n",
    "   \n",
    "print(\"Best param values: \", argmin)\n",
    "   \n",
    "# Get details from each trial run\n",
    "print (\"trials:\")\n",
    "for trial in trial_runs.trials:\n",
    "    print (\"\\n\", trial)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
